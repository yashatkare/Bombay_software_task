{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eb2a005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in .\\venv\\lib\\site-packages (4.10.0.82)\n",
      "Requirement already satisfied: numpy>=1.21.2 in .\\venv\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/ae/20/6d1a0a61d468b37a142fd90bb93c73bc1c2205db4a69ac630ed218c31612/scikit_learn-1.5.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached scikit_learn-1.5.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in .\\venv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Obtaining dependency information for scipy>=1.6.0 from https://files.pythonhosted.org/packages/4a/48/4513a1a5623a23e95f94abd675ed91cfb19989c58e9f6f7d03990f6caf3d/scipy-1.13.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached scipy-1.13.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Obtaining dependency information for joblib>=1.2.0 from https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl.metadata\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl.metadata\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.5.0-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.13.1-cp311-cp311-win_amd64.whl (46.2 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.0 scipy-1.13.1 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install scikit-learn\n",
    "!pip install flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d567c971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Building', 'Forest', 'Glacier', 'Mountains', 'Sea', 'Streets']\n",
      "Data loaded and preprocessed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_dir = \"dataset_full\"\n",
    "\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "class_names = os.listdir(data_dir)\n",
    "print(class_names)\n",
    "class_indices = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    file_names = os.listdir(class_dir)[1:] \n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(class_dir, file_name)\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.resize(image, (128, 128)) \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  \n",
    "        images.append(image)\n",
    "        labels.append(class_indices[class_name])\n",
    "\n",
    "\n",
    "images = np.array(images, dtype=np.uint8)\n",
    "labels = np.array(labels)\n",
    "\n",
    "\n",
    "images = images / 255.0\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data loaded and preprocessed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58731ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def histogram_equalization(image):\n",
    "    \"\"\"Apply histogram equalization to the image.\"\"\"\n",
    "\n",
    "    if image.dtype != np.uint8:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "\n",
    "    return cv2.equalizeHist(image)\n",
    "\n",
    "def edge_detection_canny(image, low_threshold=50, high_threshold=150):\n",
    "    \"\"\"Apply Canny edge detection.\"\"\"\n",
    "    image = (image * 255).astype(np.uint8) \n",
    "    return cv2.Canny(image, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Gaussian blur to the image.\"\"\"\n",
    "    return cv2.GaussianBlur(image, kernel_size, 0)\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in images:\n",
    "   \n",
    "        hist_eq = histogram_equalization(image)\n",
    "        gauss_blur = gaussian_blur(image)\n",
    "        canny_edges = edge_detection_canny(image)\n",
    "        \n",
    "\n",
    "        feature_vector = np.concatenate([\n",
    "            hist_eq.flatten(),\n",
    "            gauss_blur.flatten(),\n",
    "            canny_edges.flatten()\n",
    "        ])\n",
    "        \n",
    "        features.append(feature_vector)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "X_train_features = extract_features(X_train)\n",
    "X_val_features = extract_features(X_val)\n",
    "\n",
    "print(\"Feature extraction completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d584e7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality reduction completed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def apply_pca(features, n_components=100):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "    return reduced_features, pca\n",
    "\n",
    "X_train_reduced, pca = apply_pca(X_train_features)\n",
    "X_val_reduced = pca.transform(X_val_features)\n",
    "\n",
    "print(\"Dimensionality reduction completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb982a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6854146806482364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Building       0.46      0.41      0.43       112\n",
      "      Forest       0.82      0.97      0.89       534\n",
      "     Glacier       0.49      0.37      0.42       101\n",
      "   Mountains       0.45      0.67      0.54       105\n",
      "         Sea       0.33      0.16      0.21        90\n",
      "     Streets       0.78      0.33      0.46       107\n",
      "\n",
      "    accuracy                           0.69      1049\n",
      "   macro avg       0.55      0.48      0.49      1049\n",
      "weighted avg       0.67      0.69      0.66      1049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "def train_knn(X_train, y_train, n_neighbors=5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn\n",
    "\n",
    "knn_model = train_knn(X_train_reduced, y_train)\n",
    "\n",
    "\n",
    "y_val_pred = knn_model.predict(X_val_reduced)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2894a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(knn_model, f)\n",
    "\n",
    "with open('pca.pkl', 'wb') as f:\n",
    "    pickle.dump(pca, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
